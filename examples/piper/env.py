import numpy as np
from openpi_client import image_tools
from openpi_client.runtime import environment as _environment
from typing_extensions import override
import time
import threading
import cv2
import h5py
from datetime import datetime
import os

from piper_controller import PiperController
from cameras import RealSenseCamera, USBCamera


class PiperEnvironment(_environment.Environment):
    """An environment for a Piper robot arm with RealSense camera (real hardware)."""

    def __init__(
        self,
        can_port: str = "can0",
        # camera_width: int = 224,
        # camera_height: int = 224,
        camera_fps: int = 30,
        high_camera_id: int = 6,
        left_wrist_camera_id: int = 4,
        max_episode_steps: int = 500,
        initial_joint_pos: list = None,
        seed: int = 0,
        tele_mode: bool = False,
        prompt: str = "",
        watchdog_timeout: float = 5.0,
        show_usb_camera: bool = False,
        gripper_norm: bool = True,
        action_history_size: int = 30,
        action_change_threshold: float = 0.01,
        record_mode: bool = False,
        record_directory: str = "recorded_data",
    ) -> None:
        """Initialize the Piper robot environment.
        
        Args:
            can_port: CAN bus port name for the Piper robot (default "can0").
            camera_width: RealSense camera width in pixels.
            camera_height: RealSense camera height in pixels.
            camera_fps: RealSense camera frames per second.
            usb_camera_id: USB camera device ID for cam_high (default 0).
            max_episode_steps: Maximum steps per episode before auto-termination.
            initial_joint_pos: Initial joint configuration [j1, j2, j3, j4, j5, j6, gripper].
                              If None, uses [0, 0, 0, 0, 0, 0, 0.001] as default.
            seed: Random seed (for compatibility; not used in real hardware).
            tele_mode: If True, disables robot motion commands for safe testing.
            prompt: Text prompt to be included in observations.
            show_usb_camera: If True, opens an OpenCV window to preview the USB camera in real time.
            record_mode: If True, records trajectory data during episodes.
            record_directory: Directory to save recorded episodes (default "recorded_data").
        """
        np.random.seed(seed)
        self._rng = np.random.default_rng(seed)

        # Threading for parallel hardware polling
        self._obs_lock = threading.Lock()
        self._stop_event = threading.Event()
        #self._last_obs = None  # This will be updated by the background thread
        self._update_thread = None
        self._update_rate = camera_fps  # Hz
        
        # çœ‹é—¨ç‹—æœºåˆ¶ï¼šæ£€æµ‹åå°çº¿ç¨‹æ˜¯å¦å¡æ­»
        self._watchdog_timeout = watchdog_timeout
        #self._last_update_time = time.time()
        self._consecutive_failures = 0
        self._max_consecutive_failures = 10  # è¿ç»­å¤±è´¥10æ¬¡åè®¤ä¸ºè®¾å¤‡æ•…éšœ
        self._device_healthy = True
        self._robot_enabled = False

        # Initialize hardware
        self._robot = PiperController(can_port=can_port, gripper_norm=gripper_norm)
        # cannot customize the resolution of the cameras, use the minimum resolution of them.
        self._wrist_camera = USBCamera(camera_id=left_wrist_camera_id, width=320, height=240, fps=camera_fps) #RealSenseCamera(width=camera_width, height=camera_height, fps=camera_fps)
        self._high_camera = USBCamera(camera_id=high_camera_id, width=1280, height=960, fps=camera_fps)
        
        # Episode tracking
        self._done = True
        self._episode_reward = 0.0
        self._step_count = 0
        self._max_episode_steps = max_episode_steps
        
        # Default initial position
        if initial_joint_pos is None:
            self._initial_joint_pos = [0.08250172,0.28386036,-0.81074035,0.00631809,0.7380648,0.03782129,0.0] # [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001] # 
        else:
            self._initial_joint_pos = initial_joint_pos

        # Start hardware and background threads
        self._start_hardware()
        print(f"PiperEnvironment initialized with CAN port {can_port}")
        print(f"  - Wrist camera (USB ID {left_wrist_camera_id}): {320}x{240}@{camera_fps}fps")
        print(f"  - High camera (USB ID {high_camera_id}): {1280}x{960}@{camera_fps}fps")

        # Optional: record mode settings can be implemented here
        self._tele_mode = tele_mode
        
        # Store prompt for inclusion in observations
        self._prompt = prompt

        # USB ç›¸æœºé¢„è§ˆè®¾ç½®
        self._show_usb_camera = show_usb_camera
        self._usb_window_name = "USB Camera Preview"
        self._usb_window_initialized = False
        # ç¼“å­˜æ˜¾ç¤ºå°ºå¯¸ï¼ˆé«˜åˆ†è¾¨ç‡ç›¸æœºçš„ä¸€åŠï¼‰
        self._display_width = self._high_camera.width // 2
        self._display_height = self._high_camera.height // 2
        # æ˜¾ç¤ºå¸§è®¡æ•°å™¨ï¼ˆç”¨äºè·³å¸§æ˜¾ç¤ºï¼‰
        self._display_frame_counter = 0
        
        # Action å†å²é˜Ÿåˆ—ï¼šè®°å½•æœ€è¿‘æ¥æ”¶çš„åŠ¨ä½œ
        self._action_history_size = action_history_size
        self._action_history = []
        self._action_change_threshold = action_change_threshold
        
        # è½¨è¿¹è®°å½•ç›¸å…³
        self._record_mode = record_mode
        self._record_directory = record_directory
        self._episode_data = []  # å­˜å‚¨å½“å‰episodeçš„æ•°æ®
        self._last_obs = None  # å­˜å‚¨æœ€æ–°çš„observation

    def _start_hardware(self):
        """Starts camera hardware and the background observation polling thread."""
        # Start cameras
        self._wrist_camera.start()
        self._high_camera.start()
        try:
            self._robot.enable()
            self._robot_enabled = True
        except Exception as e:
            print(f"Warning during enable: {e}")
            raise RuntimeError(f"Failed to enable robot: {e}")
        # Wait a moment for cameras to initialize
        time.sleep(1.0)

        # Create and start the single polling thread
        # self._update_thread = threading.Thread(target=self._update_observation_loop, daemon=True)
        # self._update_thread.start()

    # def _update_observation_loop(self):
    #     """Continuously polls all hardware and updates the latest observation."""
    #     while not self._stop_event.is_set():
    #         start_time = time.time()
            
    #         try:
    #             # Atomically update the observation
    #             self._update_observation()
    #             # æ›´æ–°çœ‹é—¨ç‹—æ—¶é—´æˆ³
    #             self._last_update_time = time.time()
    #             # é‡ç½®è¿ç»­å¤±è´¥è®¡æ•°
    #             if self._consecutive_failures > 0:
    #                 print(f"è®¾å¤‡æ¢å¤æ­£å¸¸ï¼Œé‡ç½®å¤±è´¥è®¡æ•°")
    #             self._consecutive_failures = 0
    #         except Exception as e:
    #             print(f"âŒ è§‚æµ‹æ›´æ–°å¾ªç¯é”™è¯¯: {e}")
    #             import traceback
    #             traceback.print_exc()
    #             self._consecutive_failures += 1
                
    #             if self._consecutive_failures >= self._max_consecutive_failures:
    #                 print(f"âš ï¸ è¿ç»­å¤±è´¥ {self._consecutive_failures} æ¬¡ï¼Œæ ‡è®°è®¾å¤‡ä¸ºä¸å¥åº·çŠ¶æ€")
    #                 self._device_healthy = False
    #                 break

    #         # Sleep to maintain the desired update rate
    #         elapsed_time = time.time() - start_time
    #         sleep_time = (1.0 / self._update_rate) - elapsed_time
    #         if sleep_time > 0:
    #             time.sleep(sleep_time)
        
    #     print("âš ï¸ è§‚æµ‹æ›´æ–°çº¿ç¨‹å·²é€€å‡º")

    def _update_observation(self):
        """Gathers data from all devices and updates self._last_obs."""
        # Poll all devices and record timestamps
        start_ts = time.time()
        
        # è¯»å–å…¨å±€ç›¸æœº (å¸¦è¶…æ—¶)
        try:
            high_frame = self._high_camera.read(timeout=0.5)
            high_ts = time.time()
            if high_frame is None:
                print(f"âš ï¸ è­¦å‘Š: å…¨å±€ç›¸æœºè¯»å–è¶…æ—¶æˆ–å¤±è´¥")
        except Exception as e:
            print(f"âŒ è­¦å‘Š: å…¨å±€ç›¸æœºè¯»å–å¼‚å¸¸: {e}")
            high_frame = None
            high_ts = time.time()
        
        # è¯»å–è…•éƒ¨ç›¸æœº (å¸¦è¶…æ—¶)
        try:
            wrist_frame = self._wrist_camera.read(timeout=0.5)
            wrist_ts = time.time()
            if wrist_frame is None:
                print(f"âš ï¸ è­¦å‘Š: è…•éƒ¨ç›¸æœºè¯»å–è¶…æ—¶æˆ–å¤±è´¥")
        except Exception as e:
            print(f"âŒ è­¦å‘Š: è…•éƒ¨ç›¸æœºè¯»å–å¼‚å¸¸: {e}")
            wrist_frame = None
            wrist_ts = time.time()
        
        # è¯»å–æœºæ¢°è‡‚çŠ¶æ€
        try:
            state = self._robot.get_full_joint_status()
            robot_ts = time.time()
        except Exception as e:
            print(f"âŒ è­¦å‘Š: æœºæ¢°è‡‚çŠ¶æ€è¯»å–å¤±è´¥: {e}")
            state = [0.0] * 7
            robot_ts = time.time()
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰è®¾å¤‡éƒ½å¤±è´¥
        if high_frame is None and wrist_frame is None:
            raise RuntimeError("æ‰€æœ‰ç›¸æœºéƒ½æ— æ³•è¯»å–æ•°æ®ï¼Œå¯èƒ½è®¾å¤‡å·²æ–­å¼€è¿æ¥")
        
        #process_start_ts = time.time()
        # Process images
        wrist_img = self._process_camera_frame(
            wrist_frame, self._wrist_camera.width, self._wrist_camera.height
        )
        high_img = self._process_camera_frame(
            high_frame, self._high_camera.width, self._high_camera.height
        )

        # Assemble the observation dictionary
        obs = {
            "state": np.array(state, dtype=np.float32),
            "images": {
                "cam_left_wrist": wrist_img,
                "cam_high": high_img,
            },
            "timestamps": {
                "start": start_ts,
                "robot": robot_ts,
                "cam_left_wrist": wrist_ts,
                "cam_high": high_ts,
            },
            "prompt": self._prompt,
        }
        #process_end_ts = time.time()

        # Update the shared observation under a lock
        # with self._obs_lock:
        #     self._last_obs = obs
        #print(f"Delta time for process: {process_end_ts - process_start_ts} ")

        #display_start_ts = time.time()
        # å¯é€‰ï¼šå®æ—¶æ˜¾ç¤º USB ç›¸æœºç”»é¢
        if self._show_usb_camera:
            self._display_usb_camera_frame(high_frame)
        #display_end_ts = time.time()
        #print(f"Delta time for display: {display_end_ts - display_start_ts} ")
        
        return obs

    def _display_usb_camera_frame(self, frame: np.ndarray) -> None:
        """åœ¨å•ç‹¬çª—å£ä¸­å®æ—¶æ˜¾ç¤º USB ç›¸æœºç”»é¢ã€‚
        
        ä¼˜åŒ–ç‰ˆæœ¬ï¼š
        1. ä½¿ç”¨ç¼“å­˜çš„æ˜¾ç¤ºå°ºå¯¸ï¼Œé¿å…é‡å¤è®¡ç®—
        2. ä½¿ç”¨ INTER_AREA æ’å€¼ï¼ˆå¯¹ç¼©å°å›¾åƒæ›´å¿«ä¸”è´¨é‡æ›´å¥½ï¼‰
        3. å¯é€‰ï¼šé™ä½æ˜¾ç¤ºé¢‘ç‡ä»¥å‡å°‘å¼€é”€ï¼ˆå½“å‰æ¯å¸§éƒ½æ˜¾ç¤ºï¼‰
        """
        try:
            if frame is None:
                return

            # å¯é€‰ï¼šé™ä½æ˜¾ç¤ºé¢‘ç‡ï¼ˆæ¯2å¸§æ˜¾ç¤ºä¸€æ¬¡ï¼Œå‡å°‘50%çš„æ˜¾ç¤ºå¼€é”€ï¼‰
            # å–æ¶ˆæ³¨é‡Šä¸‹é¢ä¸¤è¡Œæ¥å¯ç”¨è·³å¸§æ˜¾ç¤º
            # self._display_frame_counter += 1
            # if self._display_frame_counter % 2 != 0:
            #     return

            if not self._usb_window_initialized:
                cv2.namedWindow(self._usb_window_name, cv2.WINDOW_NORMAL)
                cv2.resizeWindow(self._usb_window_name, self._display_width, self._display_height)
                self._usb_window_initialized = True

            # æ£€æŸ¥æ˜¯å¦éœ€è¦resizeï¼ˆå¦‚æœå·²ç»æ˜¯ç›®æ ‡å¤§å°ï¼Œè·³è¿‡ï¼‰
            original_height, original_width = frame.shape[:2]
            if original_width == self._display_width and original_height == self._display_height:
                # å·²ç»æ˜¯ç›®æ ‡å¤§å°ï¼Œç›´æ¥æ˜¾ç¤º
                cv2.imshow(self._usb_window_name, frame)
            else:
                # ä½¿ç”¨ INTER_AREA æ’å€¼ï¼ˆå¯¹ç¼©å°å›¾åƒæ›´å¿«ä¸”è´¨é‡æ›´å¥½ï¼‰
                # å¦‚æœè¿½æ±‚æè‡´é€Ÿåº¦ï¼Œå¯ä»¥ä½¿ç”¨ INTER_NEARESTï¼ˆæœ€å¿«ä½†è´¨é‡è¾ƒå·®ï¼‰
                resized_frame = cv2.resize(
                    frame, 
                    (self._display_width, self._display_height), 
                    interpolation=cv2.INTER_AREA
                )
                cv2.imshow(self._usb_window_name, resized_frame)
            
            # waitKey è¿”å› -1 è¡¨ç¤ºæ— æŒ‰é”®ï¼Œé¿å…é˜»å¡
            key = cv2.waitKey(1) & 0xFF
            if key == ord("q"):
                print("âš ï¸ æ£€æµ‹åˆ°æŒ‰é”® 'q'ï¼Œå·²å…³é—­ USB ç›¸æœºå®æ—¶é¢„è§ˆã€‚")
                self._show_usb_camera = False
                cv2.destroyWindow(self._usb_window_name)
                self._usb_window_initialized = False
        except Exception as e:
            print(f"âŒ USB ç›¸æœºé¢„è§ˆå¼‚å¸¸: {e}")
            self._show_usb_camera = False
            try:
                cv2.destroyWindow(self._usb_window_name)
            except Exception:
                pass
            self._usb_window_initialized = False

    def _process_camera_frame(self, frame: np.ndarray, width: int, height: int) -> np.ndarray:
        """Processes a raw camera frame (resize, color convert, transpose).
        
        Optimized version using OpenCV instead of PIL for better performance.
        Performance improvements:
        1. Uses cv2.resize instead of PIL (much faster)
        2. Reduces memory copies by combining operations
        3. Uses optimized interpolation methods
        """
        if frame is None:
            # If no frame available, create a black image
            frame = np.zeros((height, width, 3), dtype=np.uint8)
        
        target_size = 224
        cur_height, cur_width = frame.shape[:2]
        
        # Calculate resize ratio to maintain aspect ratio
        ratio = max(cur_width / target_size, cur_height / target_size)
        resized_height = int(cur_height / ratio)
        resized_width = int(cur_width / ratio)
        
        # Resize using OpenCV (much faster than PIL)
        # Use INTER_AREA for downscaling (better quality) or INTER_LINEAR for upscaling
        if ratio > 1.0:
            interpolation = cv2.INTER_AREA  # Better for downscaling
        else:
            interpolation = cv2.INTER_LINEAR  # Better for upscaling
        
        # Resize using OpenCV (BGR format)
        resized = cv2.resize(frame, (resized_width, resized_height), interpolation=interpolation)
        
        # Convert BGR to RGB
        resized_rgb = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
        
        # Calculate padding
        pad_h = (target_size - resized_height) // 2
        pad_w = (target_size - resized_width) // 2
        pad_h_remainder = target_size - resized_height - pad_h
        pad_w_remainder = target_size - resized_width - pad_w
        
        # Pad with zeros (black padding)
        padded = np.pad(
            resized_rgb,
            ((pad_h, pad_h_remainder), (pad_w, pad_w_remainder), (0, 0)),
            mode='constant',
            constant_values=0
        )
        
        # Convert axis order from [H, W, C] --> [C, H, W]
        return np.transpose(padded, (2, 0, 1))

    @override
    def reset(self) -> None:
        """Reset the environment: enable robot, move to initial position, reset counters."""
        # If in record mode, skip enabling and moving the robot
        if not self._tele_mode:
            # Enable robot if not already enabled
            try:
                if not self._robot_enabled:
                    self._robot.enable()
                    self._robot_enabled = True
                else:
                    print("Robot already enabled")
            except Exception as e:
                print(f"Warning during enable: {e}")
            
            # Move to initial position
            print("Resetting to initial joint position...")
            self._robot.control_full_joint(self._initial_joint_pos, velocity=100)
            time.sleep(2.0)  # wait for motion to complete and observation to be ready
        
        # Ensure the first observation is ready
        # while self._last_obs is None:
        #     time.sleep(0.1)

        self._done = False
        self._episode_reward = 0.0
        self._step_count = 0
        # æ¸…ç©º action å†å²é˜Ÿåˆ—
        self._action_history = []
        # å¦‚æœå¤„äºè®°å½•æ¨¡å¼ï¼Œåˆå§‹åŒ–episodeæ•°æ®åˆ—è¡¨
        if self._record_mode:
            self._episode_data = []
            self._last_obs = None
        print("Environment reset complete.")

    @override
    def is_episode_complete(self) -> bool:
        """Check if the episode is done (manually set or max steps reached)."""
        if self._step_count >= self._max_episode_steps:
            self._done = True
        # æ£€æŸ¥ action å†å²é˜Ÿåˆ—ä¸­çš„åŠ¨ä½œå˜åŒ–å¹…åº¦
        elif len(self._action_history) >= self._action_history_size:
            # å°†å†å²é˜Ÿåˆ—è½¬æ¢ä¸º numpy æ•°ç»„
            action_array = np.array(self._action_history)
            # è®¡ç®—æ¯ä¸ªç»´åº¦ä¸Šçš„æ ‡å‡†å·®ï¼ˆåŠ¨ä½œå˜åŒ–å¹…åº¦ï¼‰
            std_per_dim = np.std(action_array, axis=0)            
            # æ£€æŸ¥æ¯ä¸ªç»´åº¦çš„å˜åŒ–æ˜¯å¦éƒ½å°äºé˜ˆå€¼ï¼Œåªæœ‰å½“æ‰€æœ‰ç»´åº¦éƒ½æ»¡è¶³æ¡ä»¶æ—¶æ‰å®Œæˆ
            if np.all(std_per_dim < self._action_change_threshold):
                self._done = True
        
        return self._done

    @override
    def get_observation(self) -> dict:
        """Return the last observation from the background thread."""
        # æ£€æŸ¥è®¾å¤‡å¥åº·çŠ¶æ€
        if not self._device_healthy:
            raise RuntimeError("âš ï¸ è®¾å¤‡å¤„äºä¸å¥åº·çŠ¶æ€ï¼Œå¯èƒ½å·²æ–­å¼€è¿æ¥ã€‚è¯·é‡å¯ç¨‹åºã€‚")
        
        # æ£€æŸ¥çœ‹é—¨ç‹—è¶…æ—¶
        # time_since_update = time.time() - self._last_update_time
        # if time_since_update > self._watchdog_timeout:
        #     self._device_healthy = False
        #     raise RuntimeError(
        #         f"âš ï¸ çœ‹é—¨ç‹—è¶…æ—¶ï¼šåå°çº¿ç¨‹å·² {time_since_update:.2f} ç§’æ— å“åº”ï¼ˆè¶…æ—¶é˜ˆå€¼: {self._watchdog_timeout}sï¼‰ã€‚\n"
        #         f"è¿™é€šå¸¸æ„å‘³ç€è®¾å¤‡ï¼ˆç›¸æœºæˆ–æœºæ¢°è‡‚ï¼‰å·²æ–­å¼€è¿æ¥æˆ–å¡æ­»ã€‚è¯·æ£€æŸ¥ç¡¬ä»¶è¿æ¥å¹¶é‡å¯ç¨‹åºã€‚"
        #     )
        start_time = time.time()
        while time.time() - start_time < self._watchdog_timeout:
            obs = self._update_observation()
            if obs is not None:
                # å¦‚æœå¤„äºè®°å½•æ¨¡å¼ï¼Œä¿å­˜æœ€æ–°çš„observation
                if self._record_mode:
                    self._last_obs = obs.copy()
                #print(f"Delta time from observation to return: {time.time() - obs['timestamps']['robot']} ")
                return obs
            time.sleep(0.0001)
        
        raise RuntimeError("âš ï¸ çœ‹é—¨ç‹—è¶…æ—¶ï¼šåå°çº¿ç¨‹å·²æ— å“åº”ï¼ˆè¶…æ—¶é˜ˆå€¼: {self._watchdog_timeout}sï¼‰ã€‚\n"
                           "è¿™é€šå¸¸æ„å‘³ç€è®¾å¤‡ï¼ˆç›¸æœºæˆ–æœºæ¢°è‡‚ï¼‰å·²æ–­å¼€è¿æ¥æˆ–å¡æ­»ã€‚è¯·æ£€æŸ¥ç¡¬ä»¶è¿æ¥å¹¶é‡å¯ç¨‹åºã€‚")

        # with self._obs_lock:
        #     if self._last_obs is None:
        #         raise RuntimeError("è§‚æµ‹æ•°æ®å°šæœªå‡†å¤‡å¥½ã€‚è¯·è°ƒç”¨ reset() å¹¶ç­‰å¾…ã€‚")
        #     print(f"Obtained obs times used: {self._last_obs['timestamps']['robot']-self._last_obs['timestamps']['start']}")
        #     print(f"Delta with current time: {time.time() - self._last_obs['timestamps']['robot']} ")
        #     return self._last_obs.copy()


    @override
    def apply_action(self, action: dict) -> None:
        """Apply an action to the robot and update observation.
        
        Expected action format:
        {
            "actions": np.ndarray of shape (7,) containing [j1, j2, j3, j4, j5, j6, gripper]
                       where joints are in radians and gripper is opening width in meters.
        }
        """
        # Extract action (7-dim: 6 joints + gripper)
        joint_action = action.get("actions", None)
        if joint_action is None:
            raise ValueError("Action dict must contain 'actions' key with joint positions.")
        
        # Convert to list if numpy array
        if isinstance(joint_action, np.ndarray):
            joint_action = joint_action.tolist()
        
        # å¦‚æœå¤„äºè®°å½•æ¨¡å¼ï¼Œå°†æœ€æ–°çš„obså’Œå½“å‰çš„actionç»„åˆæˆä¸€ä¸ªstepå­˜å…¥æ•°æ®åº“
        if self._record_mode and self._last_obs is not None:
            step_data = {
                'observation': self._last_obs.copy(),
                'action': np.array(joint_action, dtype=np.float32)
            }
            self._episode_data.append(step_data)
        
        # Send command to robot
        try:
            if not self._tele_mode:
                self._robot.control_full_joint(joint_action, velocity=100)
        except Exception as e:
            print(f"Error applying action: {e}")
            self._done = True
        
        # å°†åŠ¨ä½œæ·»åŠ åˆ°å†å²é˜Ÿåˆ—
        action_np = np.array(joint_action, dtype=np.float32)
        self._action_history.append(action_np)
        # ä¿æŒé˜Ÿåˆ—å¤§å°ä¸è¶…è¿‡è®¾å®šå€¼
        if len(self._action_history) > self._action_history_size:
            self._action_history.pop(0)
        
        # Small delay to allow motion to start
        #time.sleep(1.0 / self._update_rate)
        
        # Observation is updated in the background, no need to call a getter here
        self._step_count += 1
        
        # Optional: compute reward (placeholder for now; extend as needed)
        # For real tasks, you might check task completion criteria here
        reward = 0.0
        self._episode_reward += reward

        #print(f"Step {self._step_count}: Applied action {joint_action}")

    def close(self) -> None:
        """Clean up: stop threads, disable robot, and stop cameras."""
        print("ğŸ”„ æ­£åœ¨å…³é—­ PiperEnvironment...")
        
        # Signal thread to stop
        self._stop_event.set()
        
        # Wait for thread to finish
        if self._update_thread:
            print("â³ ç­‰å¾…åå°çº¿ç¨‹ç»“æŸ...")
            self._update_thread.join(timeout=3)
            if self._update_thread.is_alive():
                print("âš ï¸ è­¦å‘Š: åå°çº¿ç¨‹æœªåœ¨è¶…æ—¶æ—¶é—´å†…ç»“æŸï¼ˆå¯èƒ½å¡æ­»ï¼‰")

        if not self._tele_mode:
            try:
                print("ğŸ”„ æ­£åœ¨å¤±èƒ½æœºæ¢°è‡‚...")
                if self._robot_enabled:
                    self._robot.disable()
                    self._robot_enabled = False
                    print("âœ… æœºæ¢°è‡‚å·²å¤±èƒ½")
                else:
                    print("Robot already disabled")
            except Exception as e:
                print(f"âŒ æœºæ¢°è‡‚å¤±èƒ½æ—¶å‡ºé”™: {e}")

        try:
            print("ğŸ”„ æ­£åœ¨å…³é—­è…•éƒ¨ç›¸æœº...")
            self._wrist_camera.stop()
            print("âœ… è…•éƒ¨ç›¸æœºå·²å…³é—­")
        except Exception as e:
            print(f"âŒ è…•éƒ¨ç›¸æœºå…³é—­æ—¶å‡ºé”™: {e}")
    
        try:
            print("ğŸ”„ æ­£åœ¨å…³é—­å…¨å±€ç›¸æœº...")
            self._high_camera.stop()
            print("âœ… å…¨å±€ç›¸æœºå·²å…³é—­")
        except Exception as e:
            print(f"âŒ å…¨å±€ç›¸æœºå…³é—­æ—¶å‡ºé”™: {e}")

        if self._usb_window_initialized:
            cv2.destroyWindow(self._usb_window_name)
        
        print("âœ… PiperEnvironment å·²å®Œå…¨å…³é—­")

    def _save_episode_to_hdf5(self):
        """Save the current episode data to an HDF5 file."""
        if not self._episode_data:
            print("No episode data to save.")
            return
        
        # Ensure the save directory exists
        os.makedirs(self._record_directory, exist_ok=True)
        
        # Generate a unique filename with prompt
        timestamp_str = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # å°†promptè½¬æ¢ä¸ºæ–‡ä»¶åå®‰å…¨çš„æ ¼å¼
        prompt = self._prompt if self._prompt else ""
        if prompt:
            # å°†ç©ºæ ¼æ›¿æ¢ä¸ºä¸‹åˆ’çº¿ï¼Œç§»é™¤æˆ–æ›¿æ¢ç‰¹æ®Šå­—ç¬¦
            safe_prompt = prompt.replace(" ", "_").replace("/", "_").replace("\\", "_")
            safe_prompt = safe_prompt.replace(",", "").replace(".", "")
            # é™åˆ¶é•¿åº¦ï¼ˆé¿å…æ–‡ä»¶åè¿‡é•¿ï¼‰
            max_prompt_len = 80
            if len(safe_prompt) > max_prompt_len:
                safe_prompt = safe_prompt[:max_prompt_len]
            filename = os.path.join(self._record_directory, f"episode_{timestamp_str}_{safe_prompt}.hdf5")
        else:
            filename = os.path.join(self._record_directory, f"episode_{timestamp_str}.hdf5")
        
        print(f"Saving episode to {filename}...")
        
        # å°†episode_dataè½¬æ¢ä¸ºcollect_data.pyä¸­çš„æ ¼å¼ï¼ˆåªæœ‰observationï¼‰
        episode_obs_data = []
        for step_data in self._episode_data:
            episode_obs_data.append(step_data['observation'])
        
        # å¦‚æœæ²¡æœ‰observationæ•°æ®ï¼Œç›´æ¥è¿”å›
        if not episode_obs_data:
            print("No observation data to save.")
            return
        
        with h5py.File(filename, "w") as f:
            # Pre-allocate numpy arrays by inspecting the first observation
            first_obs = episode_obs_data[0]
            first_action = self._episode_data[0]['action']
            num_steps = len(episode_obs_data)
            
            # Create datasets based on the expected structure
            obs_group = f.create_group("observations")
            img_group = obs_group.create_group("images")
            
            state_shape = first_obs['state'].shape
            obs_group.create_dataset("qpos", (num_steps,) + state_shape, dtype=first_obs['state'].dtype)
            
            # Action from the actual action stored in _episode_data
            action_shape = first_action.shape
            f.create_dataset("action", (num_steps,) + action_shape, dtype=first_action.dtype)
            
            for cam_name, img in first_obs['images'].items():
                img_shape = img.shape
                img_group.create_dataset(cam_name, (num_steps,) + img_shape, dtype=img.dtype)
                
            # Save the instruction prompt
            if 'prompt' in first_obs:
                prompt_len = len(first_obs['prompt'])
                fix_prompt_type = np.dtype(f'S{prompt_len}')
                f.create_dataset("task", (num_steps,), dtype=fix_prompt_type)
            
            # Save timestamps if available
            timestamps_group = None
            if 'timestamps' in first_obs and first_obs['timestamps']:
                timestamps_group = obs_group.create_group("timestamps")
                # Create datasets for each timestamp field
                for ts_key in first_obs['timestamps'].keys():
                    timestamps_group.create_dataset(ts_key, (num_steps,), dtype=np.float64)
            
            # Populate the datasets
            for i in range(num_steps):
                # Populate observations
                obs_group['qpos'][i] = episode_obs_data[i]['state']
                
                # Action from the actual action stored in _episode_data
                f['action'][i] = self._episode_data[i]['action']
                
                for cam_name, img in episode_obs_data[i]['images'].items():
                    img_group[cam_name][i] = img
                if 'prompt' in first_obs:
                    f['task'][i] = episode_obs_data[i]['prompt']
                
                # Save timestamps
                if timestamps_group is not None and 'timestamps' in episode_obs_data[i]:
                    for ts_key, ts_value in episode_obs_data[i]['timestamps'].items():
                        if ts_key in timestamps_group:
                            timestamps_group[ts_key][i] = ts_value
                    
        print(f"Successfully saved {num_steps} steps.")
        # æ¸…ç©ºepisodeæ•°æ®
        self._episode_data = []

    def __del__(self):
        """Destructor to ensure cleanup on object deletion."""
        try:
            self.close()
        except Exception:
            pass
