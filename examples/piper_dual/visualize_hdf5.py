#!/usr/bin/env python3
"""
å¯è§†åŒ–PiperDualEnvironment record_modeä¿å­˜çš„HDF5æ–‡ä»¶ï¼š
1. ç»˜åˆ¶14ä¸ªå…³èŠ‚è§’åº¦çš„æ—¶åºå˜åŒ–æ›²çº¿å›¾
2. å°†å›¾ç‰‡åºåˆ—åˆæˆä¸ºè§†é¢‘å¹¶æ”¯æŒé¢„è§ˆ/ä¿å­˜
3. æ”¯æŒæŒ‡å®šç›¸æœºï¼ˆcam_high/cam_left_wrist/cam_right_wristï¼‰
"""
import os
import argparse
import h5py
import numpy as np
import cv2
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼ˆå¯é€‰ï¼Œæ ¹æ®éœ€è¦è°ƒæ•´ï¼‰
plt.rcParams['font.sans-serif'] = ['DejaVu Sans']  # è‹±æ–‡é€šç”¨
# plt.rcParams['font.sans-serif'] = ['SimHei']  # ä¸­æ–‡Windows
# plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

class HDF5Visualizer:
    def __init__(self, hdf5_path):
        """åˆå§‹åŒ–å¯è§†åŒ–å™¨
        Args:
            hdf5_path: HDF5æ–‡ä»¶è·¯å¾„
        """
        self.hdf5_path = hdf5_path
        self.file = None
        self.qpos_data = None  # å…³èŠ‚æ•°æ® (num_steps, 14)
        self.images_data = {}  # å›¾åƒæ•°æ® {cam_name: (num_steps, 224, 224, 3)}
        self.task = None       # ä»»åŠ¡æè¿°
        self.num_steps = 0     # æ€»æ­¥æ•°
        self.fps = 30          # é»˜è®¤å¸§ç‡ï¼ˆä¸é‡‡é›†æ—¶ä¸€è‡´ï¼‰
        
        # å…³èŠ‚åç§°ï¼ˆé€‚é…PiperåŒè‡‚ï¼šå·¦è‡‚7ä¸ª+å³è‡‚7ä¸ªï¼‰
        self.joint_names = [
            # å·¦è‡‚å…³èŠ‚
            'Left J1', 'Left J2', 'Left J3', 'Left J4', 'Left J5', 'Left J6', 'Left Gripper',
            # å³è‡‚å…³èŠ‚
            'Right J1', 'Right J2', 'Right J3', 'Right J4', 'Right J5', 'Right J6', 'Right Gripper'
        ]
        
        # åŠ è½½æ•°æ®
        self._load_data()

    def _load_data(self):
        """ä»HDF5æ–‡ä»¶åŠ è½½æ•°æ®"""
        try:
            self.file = h5py.File(self.hdf5_path, 'r')
            print(f"âœ… æˆåŠŸåŠ è½½HDF5æ–‡ä»¶: {self.hdf5_path}")
            
            # åŠ è½½å…³èŠ‚æ•°æ®
            if 'observations/qpos' in self.file:
                self.qpos_data = self.file['observations/qpos'][:]
                self.num_steps = self.qpos_data.shape[0]
                print(f"ğŸ“Š å…³èŠ‚æ•°æ®: {self.qpos_data.shape} (æ­¥æ•°Ã—å…³èŠ‚æ•°)")
            else:
                raise ValueError("HDF5æ–‡ä»¶ä¸­æœªæ‰¾åˆ°å…³èŠ‚æ•°æ® (observations/qpos)")
            
            # åŠ è½½å›¾åƒæ•°æ®
            if 'observations/images' in self.file:
                img_group = self.file['observations/images']
                for cam_name in img_group.keys():
                    self.images_data[cam_name] = img_group[cam_name][:]
                    print(f"ğŸ–¼ï¸ {cam_name} å›¾åƒæ•°æ®: {self.images_data[cam_name].shape}")
            
            # åŠ è½½ä»»åŠ¡æè¿°
            if 'task' in self.file:
                self.task = self.file['task'][0].decode('utf-8') if isinstance(self.file['task'][0], bytes) else self.file['task'][0]
                print(f"ğŸ¯ ä»»åŠ¡æè¿°: {self.task}")
            
        except Exception as e:
            print(f"âŒ åŠ è½½HDF5æ–‡ä»¶å¤±è´¥: {e}")
            raise

    def plot_joint_curves(self, save_path=None):
        """ç»˜åˆ¶å…³èŠ‚è§’åº¦å˜åŒ–æ›²çº¿å›¾
        Args:
            save_path: å›¾ç‰‡ä¿å­˜è·¯å¾„ï¼ˆNoneåˆ™æ˜¾ç¤ºï¼‰
        """
        if self.qpos_data is None:
            print("âŒ æ— å…³èŠ‚æ•°æ®å¯ç»˜åˆ¶")
            return
        
        # åˆ›å»ºç”»å¸ƒï¼ˆ2è¡Œ1åˆ—ï¼Œä¸ŠåŠéƒ¨åˆ†å·¦è‡‚ï¼Œä¸‹åŠéƒ¨åˆ†å³è‡‚ï¼‰
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10), sharex=True)
        fig.suptitle(f'Joint Angle Changes\nTask: {self.task}', fontsize=16, fontweight='bold')
        
        # æ—¶é—´è½´ï¼ˆæ­¥æ•°ï¼‰
        time_steps = np.arange(self.num_steps)
        
        # ç»˜åˆ¶å·¦è‡‚å…³èŠ‚ï¼ˆå‰7ä¸ªï¼‰
        colors = plt.cm.Set1(np.linspace(0, 1, 7))
        for i in range(7):
            ax1.plot(time_steps, self.qpos_data[:, i], label=self.joint_names[i], color=colors[i], linewidth=1.5)
        ax1.set_title('Left Arm Joints', fontsize=14)
        ax1.set_ylabel('Joint Angle (rad)', fontsize=12)
        ax1.grid(True, alpha=0.3)
        ax1.legend(loc='upper right', fontsize=8)
        
        # ç»˜åˆ¶å³è‡‚å…³èŠ‚ï¼ˆå7ä¸ªï¼‰
        colors = plt.cm.Set2(np.linspace(0, 1, 7))
        for i in range(7, 14):
            ax2.plot(time_steps, self.qpos_data[:, i], label=self.joint_names[i], color=colors[i-7], linewidth=1.5)
        ax2.set_title('Right Arm Joints', fontsize=14)
        ax2.set_xlabel('Time Step', fontsize=12)
        ax2.set_ylabel('Joint Angle (rad)', fontsize=12)
        ax2.grid(True, alpha=0.3)
        ax2.legend(loc='upper right', fontsize=8)
        
        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout()
        
        # ä¿å­˜æˆ–æ˜¾ç¤º
        if save_path:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ… å…³èŠ‚æ›²çº¿å›¾å·²ä¿å­˜è‡³: {save_path}")
        else:
            plt.show()
        
        plt.close()

    def make_video_from_images(self, cam_name='cam_high', save_path=None, preview=True):
        """å°†å›¾ç‰‡åºåˆ—åˆæˆä¸ºè§†é¢‘
        Args:
            cam_name: ç›¸æœºåç§°ï¼ˆcam_high/cam_left_wrist/cam_right_wristï¼‰
            save_path: è§†é¢‘ä¿å­˜è·¯å¾„ï¼ˆNoneåˆ™ä»…é¢„è§ˆï¼‰
            preview: æ˜¯å¦å®æ—¶é¢„è§ˆ
        """
        if cam_name not in self.images_data:
            print(f"âŒ æ— {cam_name}ç›¸æœºæ•°æ®ï¼Œå¯ç”¨ç›¸æœº: {list(self.images_data.keys())}")
            return
        
        images = self.images_data[cam_name]
        # å›¾åƒæ ¼å¼ä¸º (num_steps, C, H, W)ï¼Œéœ€è¦è·å–æ­£ç¡®çš„å°ºå¯¸
        height, width = images.shape[2], images.shape[3]
        
        # è§†é¢‘ç¼–ç å™¨
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        
        # é¢„è§ˆçª—å£è®¾ç½®
        if preview:
            cv2.namedWindow(f'Video Preview: {cam_name}', cv2.WINDOW_NORMAL)
            cv2.resizeWindow(f'Video Preview: {cam_name}', 800, 800)
        
        # è§†é¢‘å†™å…¥å™¨ï¼ˆå¦‚æœéœ€è¦ä¿å­˜ï¼‰
        video_writer = None
        if save_path:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            video_writer = cv2.VideoWriter(save_path, fourcc, self.fps, (width, height))
            print(f"ğŸ“¹ å¼€å§‹ç”Ÿæˆè§†é¢‘: {save_path}")
        
        # é€å¸§å¤„ç†ï¼ˆRGBâ†’BGRï¼Œé€‚é…OpenCVï¼‰
        for i, frame in enumerate(images):
            # HDF5ä¸­ä¿å­˜çš„æ˜¯RGBï¼Œè½¬æ¢ä¸ºBGRç”¨äºOpenCV
            frame = np.transpose(frame, (1, 2, 0))
            frame_bgr = cv2.cvtColor(frame.astype(np.uint8), cv2.COLOR_RGB2BGR)
            
            # å†™å…¥è§†é¢‘
            if video_writer:
                video_writer.write(frame_bgr)
            
            # é¢„è§ˆæ˜¾ç¤º
            if preview:
                cv2.imshow(f'Video Preview: {cam_name}', frame_bgr)
                # æŒ‰qé€€å‡ºé¢„è§ˆ
                if cv2.waitKey(int(1000/self.fps)) & 0xFF == ord('q'):
                    print("âš ï¸ é¢„è§ˆå·²ç»ˆæ­¢")
                    break
        
        # é‡Šæ”¾èµ„æº
        if video_writer:
            video_writer.release()
            print(f"âœ… è§†é¢‘å·²ä¿å­˜è‡³: {save_path}")
        if preview:
            cv2.destroyAllWindows()

    def close(self):
        """å…³é—­HDF5æ–‡ä»¶"""
        if self.file:
            self.file.close()

def main():
    # å‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='å¯è§†åŒ–PiperåŒè‡‚HDF5å½•åˆ¶æ–‡ä»¶')
    parser.add_argument('--hdf5_path', required=True, help='HDF5æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--joint_plot', action='store_true', help='ç»˜åˆ¶å…³èŠ‚å˜åŒ–æ›²çº¿å›¾')
    parser.add_argument('--joint_save_path', default='output/joint_curves.png', help='å…³èŠ‚å›¾ä¿å­˜è·¯å¾„')
    parser.add_argument('--make_video', action='store_true', help='ç”Ÿæˆè§†é¢‘')
    parser.add_argument('--cam_name', default='cam_high', help='ç›¸æœºåç§°: cam_high/cam_left_wrist/cam_right_wrist')
    parser.add_argument('--video_save_path', default='output/preview_video.mp4', help='è§†é¢‘ä¿å­˜è·¯å¾„')
    parser.add_argument('--fps', type=int, default=30, help='è§†é¢‘å¸§ç‡')
    parser.add_argument('--no_preview', action='store_true', help='ä¸é¢„è§ˆè§†é¢‘')
    parser.add_argument('--all_cameras', action='store_true', help='ä¿å­˜æ‰€æœ‰ç›¸æœºè§†é¢‘åˆ°outputæ–‡ä»¶å¤¹')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–å¯è§†åŒ–å™¨
    visualizer = HDF5Visualizer(args.hdf5_path)
    visualizer.fps = args.fps
    
    # ç»˜åˆ¶å…³èŠ‚æ›²çº¿å›¾
    if args.joint_plot:
        visualizer.plot_joint_curves(save_path=args.joint_save_path)
    
    # ä¿å­˜æ‰€æœ‰ç›¸æœºè§†é¢‘
    if args.all_cameras:
        for cam_name in visualizer.images_data.keys():
            video_path = f'output/{cam_name}_video.mp4'
            visualizer.make_video_from_images(
                cam_name=cam_name,
                save_path=video_path,
                preview=False
            )
    # ç”Ÿæˆå•ä¸ªç›¸æœºè§†é¢‘
    elif args.make_video:
        visualizer.make_video_from_images(
            cam_name=args.cam_name,
            save_path=args.video_save_path,
            preview=not args.no_preview
        )
    
    # å…³é—­æ–‡ä»¶
    visualizer.close()
    print("âœ… å¯è§†åŒ–å®Œæˆ")

if __name__ == '__main__':
    main()