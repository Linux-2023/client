#!/usr/bin/env python3
"""Diagnostics for Segment-Match50 diffusion score.

This script expects an out-cache-dir generated by:
  scripts/estimate_vjepa_value_hdf5.py --value-method segment_match50 --segment-match-score diffusion

It will:
1) Load diffusion caches (scaler/pca/models/train) and compute a segment confusion matrix on success_ref samples.
2) Summarize rollout cost distributions (success vs failure) from episode_values/*.npz.
3) Optionally recompute and plot a cost heatmap for a few rollout episodes (window x segment).
"""

from __future__ import annotations

import dataclasses
import hashlib
import json
import math
from pathlib import Path
from typing import Any, Literal

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import tyro


def _repo_root() -> Path:
    return Path(__file__).resolve().parents[1]


def _resolve_path(p: str | Path | None) -> Path | None:
    if p is None:
        return None
    pp = Path(p)
    return pp if pp.is_absolute() else (_repo_root() / pp).resolve()


def _read_json(path: Path) -> dict[str, Any]:
    return json.loads(path.read_text(encoding="utf-8"))


def _write_json(path: Path, obj: dict[str, Any]) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(json.dumps(obj, indent=2, ensure_ascii=False), encoding="utf-8")


def _load_npz_dict(path: Path) -> dict[str, Any] | None:
    if not path.exists():
        return None
    try:
        z = np.load(str(path), allow_pickle=True)
        out = {k: z[k] for k in z.files}
        z.close()
        return out
    except Exception:
        return None


def _decode_bytes(x: Any) -> str:
    if isinstance(x, bytes):
        return x.decode("utf-8", errors="ignore")
    if isinstance(x, np.bytes_):
        return bytes(x).decode("utf-8", errors="ignore")
    if isinstance(x, np.ndarray) and x.shape == ():
        try:
            return _decode_bytes(x.item())
        except Exception:
            return str(x)
    return str(x)


def _sha1_short(s: str) -> str:
    return hashlib.sha1(s.encode("utf-8")).hexdigest()[:10]


def _l2_normalize(x: np.ndarray, eps: float = 1e-12) -> np.ndarray:
    x = np.asarray(x, dtype=np.float32)
    if x.ndim == 1:
        n = float(np.linalg.norm(x))
        return x / max(float(eps), n)
    if x.ndim == 2:
        n = np.linalg.norm(x, axis=1, keepdims=True).astype(np.float32)
        return x / np.maximum(n, float(eps))
    raise ValueError(f"Expected 1D/2D array, got {x.shape}")


def _pca_transform(pca: dict[str, Any] | None, X_std: np.ndarray) -> np.ndarray:
    X_std = np.asarray(X_std, dtype=np.float32)
    if pca is None:
        return X_std
    mean = np.asarray(pca.get("mean", 0.0), dtype=np.float32).reshape(-1)
    comps = np.asarray(pca.get("components", 0.0), dtype=np.float32)
    return ((X_std - mean) @ comps.T).astype(np.float32)


class _SinusoidalPosEmb(nn.Module):
    def __init__(self, dim: int) -> None:
        super().__init__()
        self.dim = int(dim)

    def forward(self, t: torch.Tensor) -> torch.Tensor:
        half = int(self.dim // 2)
        if half <= 0:
            return torch.zeros((t.shape[0], 0), device=t.device, dtype=torch.float32)
        t = t.to(torch.float32)
        freqs = torch.exp(torch.arange(half, device=t.device, dtype=torch.float32) * (-math.log(10000.0) / float(max(1, half - 1))))
        args = t[:, None] * freqs[None, :]
        emb = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)
        if int(emb.shape[1]) < int(self.dim):
            emb = torch.cat([emb, torch.zeros((emb.shape[0], int(self.dim) - int(emb.shape[1])), device=t.device, dtype=emb.dtype)], dim=-1)
        return emb


class _ResidualMLPBlock(nn.Module):
    def __init__(self, dim: int) -> None:
        super().__init__()
        self.norm = nn.LayerNorm(int(dim))
        self.ff = nn.Sequential(
            nn.Linear(int(dim), int(dim) * 4),
            nn.Mish(),
            nn.Linear(int(dim) * 4, int(dim)),
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.norm(x + self.ff(x))


class _CondDiffusionDenoiser(nn.Module):
    def __init__(self, *, dim_in: int, num_segments: int, hidden_dim: int, num_layers: int) -> None:
        super().__init__()
        self.in_proj = nn.Linear(int(dim_in), int(hidden_dim))
        self.time_mlp = nn.Sequential(
            _SinusoidalPosEmb(int(hidden_dim)),
            nn.Linear(int(hidden_dim), int(hidden_dim)),
            nn.Mish(),
            nn.Linear(int(hidden_dim), int(hidden_dim)),
        )
        self.seg_emb = nn.Embedding(int(num_segments), int(hidden_dim))
        self.blocks = nn.ModuleList([_ResidualMLPBlock(int(hidden_dim)) for _ in range(int(max(1, num_layers)))])
        self.out_proj = nn.Linear(int(hidden_dim), int(dim_in))

    def forward(self, x: torch.Tensor, t: torch.Tensor, seg_id: torch.Tensor) -> torch.Tensor:
        h = self.in_proj(x)
        h = h + self.time_mlp(t) + self.seg_emb(seg_id)
        for blk in self.blocks:
            h = blk(h)
        return self.out_proj(h)


def _diffusion_precompute(timesteps: int, device: torch.device, beta_start: float = 1e-4, beta_end: float = 0.02) -> dict[str, torch.Tensor]:
    T = int(max(1, timesteps))
    betas = torch.linspace(float(beta_start), float(beta_end), T, device=device, dtype=torch.float32)
    alphas = 1.0 - betas
    alpha_cumprod = torch.cumprod(alphas, dim=0)
    return {
        "sqrt_alpha_cumprod": torch.sqrt(alpha_cumprod),
        "sqrt_one_minus_alpha_cumprod": torch.sqrt(1.0 - alpha_cumprod),
    }


def _diffusion_cost_matrix(
    *,
    model: _CondDiffusionDenoiser,
    sched: dict[str, torch.Tensor],
    X_lat: np.ndarray,
    num_segments: int,
    t_eval: int,
    noise_samples: int,
    device: torch.device,
    max_eval_batch: int = 8192,
) -> np.ndarray:
    X_lat = np.asarray(X_lat, dtype=np.float32)
    K = int(X_lat.shape[0])
    N = int(num_segments)
    if K <= 0:
        return np.zeros((0, N), dtype=np.float32)
    t_eval = int(max(0, min(int(t_eval), int(sched["sqrt_alpha_cumprod"].shape[0]) - 1)))
    s1 = sched["sqrt_alpha_cumprod"][t_eval]
    s2 = sched["sqrt_one_minus_alpha_cumprod"][t_eval]
    n_noise = int(max(1, noise_samples))
    seg_block = int(max(1, int(max_eval_batch // max(1, K))))

    X0 = torch.from_numpy(X_lat).to(device=device, dtype=torch.float32)
    cost_acc = torch.zeros((K, N), device=device, dtype=torch.float32)
    model.eval()
    with torch.inference_mode():
        for _ in range(n_noise):
            noise = torch.randn_like(X0)
            xt = s1 * X0 + s2 * noise
            for n0 in range(0, N, seg_block):
                n1 = min(N, n0 + seg_block)
                nb = int(n1 - n0)
                xt_rep = xt.repeat(nb, 1)
                noise_rep = noise.repeat(nb, 1)
                seg_ids = torch.arange(n0, n1, device=device, dtype=torch.int64).repeat_interleave(K)
                t_rep = torch.full((int(K * nb),), int(t_eval), device=device, dtype=torch.int64)
                pred = model(xt_rep, t_rep, seg_ids)
                mse = ((pred - noise_rep) ** 2).mean(dim=1).reshape(nb, K).transpose(0, 1)
                cost_acc[:, n0:n1] += mse
    return (cost_acc / float(n_noise)).detach().cpu().numpy().astype(np.float32)


def _episode_embed_cache_path(embed_cache_dir: Path, hdf5_path: Path) -> Path:
    st = hdf5_path.stat()
    s = f"{hdf5_path.resolve()}|{int(st.st_size)}|{int(st.st_mtime_ns)}"
    ep_id = hashlib.sha1(s.encode("utf-8")).hexdigest()[:10]
    return embed_cache_dir / f"{hdf5_path.stem}__{ep_id}.npz"


def _locate_episode_embed_cache(embed_cache_dir: Path, hdf5_path: Path) -> Path | None:
    cand = _episode_embed_cache_path(embed_cache_dir, hdf5_path)
    if cand.exists():
        return cand
    matches = list(embed_cache_dir.glob(f"{hdf5_path.stem}__*.npz"))
    if not matches:
        return None
    return max(matches, key=lambda p: p.stat().st_mtime_ns if hasattr(p.stat(), "st_mtime_ns") else p.stat().st_mtime)


def _load_series_arrays(cache_path: Path, *, series: str) -> tuple[np.ndarray | None, np.ndarray | None, np.ndarray | None, np.ndarray | None]:
    z = np.load(str(cache_path), allow_pickle=True)
    try:
        th = z.get(f"{series}_t_high", None)
        eh = z.get(f"{series}_emb_high", None)
        tw = z.get(f"{series}_t_wrist", None)
        ew = z.get(f"{series}_emb_wrist", None)
        return th, eh, tw, ew
    finally:
        z.close()


@dataclasses.dataclass(frozen=True)
class Args:
    out_cache_dir: Path
    task: str | None = None
    # Confusion matrix evaluation
    max_train_samples: int = 5000
    seed: int = 0
    t_eval: int | None = None
    noise_samples: int | None = None
    # Heatmap
    heatmap_num_episodes: int = 2
    heatmap_kind: Literal["any", "success", "failure"] = "any"


def main(args: Args) -> None:
    out_dir = Path(args.out_cache_dir)
    meta = _read_json(out_dir / "vjepa_value_metadata.json")
    camera_mode = str(meta.get("camera_mode", "high"))
    camera_fusion = str(meta.get("camera_fusion", "dist_min"))
    num_segments = int(meta.get("segment_match_num_segments", 50))
    win_stride = int(meta.get("segment_match_window_stride", 6))
    win_series = f"win{num_segments}s{win_stride}"

    embed_cache_dir = _resolve_path(meta.get("embed_cache_dir"))
    if embed_cache_dir is None or not embed_cache_dir.exists():
        raise FileNotFoundError(f"embed_cache_dir missing: {embed_cache_dir}")

    # Load diffusion caches
    b_sc = _load_npz_dict(out_dir / "segmatch50_diffusion_scaler.npz")
    b_pc = _load_npz_dict(out_dir / "segmatch50_diffusion_pca.npz")
    b_md = _load_npz_dict(out_dir / "segmatch50_diffusion_models.npz")
    b_tr = _load_npz_dict(out_dir / "segmatch50_diffusion_train.npz")
    if b_sc is None or b_pc is None or b_md is None or b_tr is None:
        raise FileNotFoundError("Missing diffusion cache files under out-cache-dir. Did you run --segment-match-score diffusion?")

    cfg_id = _decode_bytes(b_sc.get("diffusion_cfg_id", ""))
    if cfg_id != _decode_bytes(b_pc.get("diffusion_cfg_id", "")) or cfg_id != _decode_bytes(b_md.get("diffusion_cfg_id", "")):
        raise RuntimeError("Diffusion cache cfg_id mismatch among scaler/pca/models.")
    scaler_blob = b_sc["scaler"].item()
    pca_blob = b_pc["pca"].item()
    models_blob = b_md["models"].item()
    train_blob = b_tr["train"].item()

    # Determine task
    tasks = sorted(list(train_blob.keys()))
    if not tasks:
        raise RuntimeError("No tasks in segmatch50_diffusion_train.npz")
    task = args.task or tasks[0]
    if task not in train_blob:
        raise KeyError(f"Task {task!r} not found. Available: {tasks[:8]}{'...' if len(tasks)>8 else ''}")

    # Inference hyperparams (default to metadata, allow override)
    T = int(meta.get("segment_match_diffusion_timesteps", 100))
    t_eval = int(args.t_eval) if args.t_eval is not None else int(meta.get("segment_match_diffusion_t_eval", 20))
    noise_samples = int(args.noise_samples) if args.noise_samples is not None else int(meta.get("segment_match_diffusion_noise_samples", 1))

    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    sched = _diffusion_precompute(T, device=device)

    # Model loader cache
    model_cache: dict[tuple[str, str], _CondDiffusionDenoiser] = {}

    def _get_model(task_name: str, key_name: str) -> _CondDiffusionDenoiser:
        ck = (str(task_name), str(key_name))
        m = model_cache.get(ck)
        if m is not None:
            return m
        rel = models_blob.get(str(task_name), {}).get(str(key_name))
        if not rel:
            raise RuntimeError(f"Missing model for task={task_name!r} key={key_name!r}")
        ckpt = torch.load(str((out_dir / str(rel)).resolve()), map_location=device)
        dim_in = int(ckpt.get("dim_in", 0))
        hidden_dim = int(ckpt.get("hidden_dim", 256))
        num_layers = int(ckpt.get("num_layers", 4))
        nseg = int(ckpt.get("num_segments", num_segments))
        if dim_in <= 0 or nseg != int(num_segments):
            raise RuntimeError("Bad checkpoint dims")
        model = _CondDiffusionDenoiser(dim_in=dim_in, num_segments=int(num_segments), hidden_dim=hidden_dim, num_layers=num_layers).to(device)
        model.load_state_dict(ckpt["state_dict"], strict=True)
        model.eval()
        model_cache[ck] = model
        return model

    def _preprocess(task_name: str, key_name: str, X_raw: np.ndarray) -> np.ndarray:
        sc = scaler_blob.get(str(task_name), {}).get(str(key_name))
        if sc is None:
            raise RuntimeError(f"Missing scaler for task={task_name!r} key={key_name!r}")
        mean = np.asarray(sc["mean"], dtype=np.float32).reshape(-1)
        std = np.asarray(sc["std"], dtype=np.float32).reshape(-1)
        use_l2 = bool(sc.get("l2_normalize", False))
        X = np.asarray(X_raw, dtype=np.float32)
        if use_l2:
            X = _l2_normalize(X)
        X_std = ((X - mean.reshape(1, -1)) / np.maximum(std.reshape(1, -1), 1e-6)).astype(np.float32)
        pca = pca_blob.get(str(task_name), {}).get(str(key_name))
        return _pca_transform(pca, X_std).astype(np.float32)

    # 1) Confusion matrix on success_ref samples (train blob)
    # Determine which key(s) to use for confusion (match the runtime fusion semantics)
    if camera_mode == "both" and camera_fusion in ("dist_min", "dist_mean"):
        key_main = "high+wrist"
        Xh = np.asarray(train_blob[task]["high"]["X"], dtype=np.float32)
        yh = np.asarray(train_blob[task]["high"]["seg_id"], dtype=np.int32).reshape(-1)
        Xw = np.asarray(train_blob[task]["wrist"]["X"], dtype=np.float32)
        yw = np.asarray(train_blob[task]["wrist"]["seg_id"], dtype=np.int32).reshape(-1)
        m = int(min(len(yh), len(yw), int(args.max_train_samples)))
        Xh = Xh[:m]
        Xw = Xw[:m]
        y = yh[:m]
        # X already in latent space in train blob; we can use it directly.
        ch = _diffusion_cost_matrix(model=_get_model(task, "high"), sched=sched, X_lat=Xh, num_segments=num_segments, t_eval=t_eval, noise_samples=noise_samples, device=device)
        cw = _diffusion_cost_matrix(model=_get_model(task, "wrist"), sched=sched, X_lat=Xw, num_segments=num_segments, t_eval=t_eval, noise_samples=noise_samples, device=device)
        cost = np.minimum(ch, cw) if camera_fusion == "dist_min" else (0.5 * (ch + cw))
    else:
        # single key (fused or single)
        if camera_mode == "both" and camera_fusion in ("emb_mean", "emb_concat"):
            key_main = "fused"
        else:
            key_main = "single"
        X = np.asarray(train_blob[task][key_main]["X"], dtype=np.float32)
        y = np.asarray(train_blob[task][key_main]["seg_id"], dtype=np.int32).reshape(-1)
        m = int(min(len(y), int(args.max_train_samples)))
        X = X[:m]
        y = y[:m]
        cost = _diffusion_cost_matrix(model=_get_model(task, key_main), sched=sched, X_lat=X, num_segments=num_segments, t_eval=t_eval, noise_samples=noise_samples, device=device)

    pred = np.argmin(cost, axis=1).astype(np.int32)
    conf = np.zeros((num_segments, num_segments), dtype=np.int32)
    for yt, yp in zip(y.tolist(), pred.tolist(), strict=False):
        if 0 <= int(yt) < num_segments and 0 <= int(yp) < num_segments:
            conf[int(yt), int(yp)] += 1
    acc = float(np.mean((pred == y).astype(np.float32))) if y.size else 0.0

    # Save confusion matrix + simple heatmap
    out_npz = out_dir / f"segmatch50_diffusion_confusion__{_sha1_short(task)}__{key_main}.npz"
    np.savez_compressed(str(out_npz), cfg_id=np.asarray(str(cfg_id)), task=np.asarray(str(task)), key=np.asarray(str(key_main)), conf=conf, acc=np.asarray(acc, dtype=np.float32))

    conf_png = None
    try:
        import matplotlib.pyplot as plt

        fig = plt.figure(figsize=(8, 7))
        ax = fig.add_subplot(1, 1, 1)
        im = ax.imshow(conf.astype(np.float32), aspect="auto", origin="lower")
        fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
        ax.set_title(f"Diffusion seg confusion (task={task})\\nkey={key_main}  acc={acc:.3f}  t_eval={t_eval}  noise_samples={noise_samples}")
        ax.set_xlabel("pred_seg")
        ax.set_ylabel("true_seg")
        fig.tight_layout()
        conf_png = out_dir / f"segmatch50_diffusion_confusion__{_sha1_short(task)}__{key_main}.png"
        fig.savefig(str(conf_png), dpi=200)
        plt.close(fig)
    except Exception:
        conf_png = None

    # 2) Rollouts cost distribution (from episode_values/*.npz)
    succ_cost: list[float] = []
    fail_cost: list[float] = []
    ep_dir = out_dir / "episode_values"
    for ep_npz in sorted(ep_dir.glob("*.npz")):
        z = np.load(str(ep_npz), allow_pickle=True)
        try:
            if _decode_bytes(z.get("segment_match_score", "")) != "diffusion":
                continue
            is_succ = bool(int(np.asarray(z.get("is_success", 0)).item()) != 0)
            v = np.asarray(z.get("match_cost_sparse", []), dtype=np.float32).reshape(-1)
            if v.size == 0:
                continue
            mcost = float(np.mean(v))
            (succ_cost if is_succ else fail_cost).append(mcost)
        finally:
            z.close()

    hist_png = None
    if succ_cost or fail_cost:
        try:
            import matplotlib.pyplot as plt

            fig = plt.figure(figsize=(9, 5))
            ax = fig.add_subplot(1, 1, 1)
            if succ_cost:
                ax.hist(np.asarray(succ_cost, dtype=np.float32), bins=30, alpha=0.6, density=True, label=f"success (n={len(succ_cost)})")
            if fail_cost:
                ax.hist(np.asarray(fail_cost, dtype=np.float32), bins=30, alpha=0.6, density=True, label=f"failure (n={len(fail_cost)})")
            ax.set_title("Rollouts mean diffusion match_cost_sparse distribution")
            ax.set_xlabel("mean(match_cost_sparse)")
            ax.set_ylabel("density")
            ax.grid(True, alpha=0.25)
            ax.legend(loc="best")
            fig.tight_layout()
            hist_png = out_dir / "segmatch50_diffusion_rollouts_cost_hist.png"
            fig.savefig(str(hist_png), dpi=200)
            plt.close(fig)
        except Exception:
            hist_png = None

    # 3) Optional heatmap on a few rollout episodes (recompute cost_mat)
    # We pick episodes from episode_values and locate their embed cache.
    heatmap_paths: list[str] = []
    if int(args.heatmap_num_episodes) > 0:
        # Collect candidates
        cands: list[Path] = []
        for ep_npz in sorted(ep_dir.glob("*.npz")):
            z = np.load(str(ep_npz), allow_pickle=True)
            try:
                src = _decode_bytes(z.get("source", ""))
                if not str(src).startswith("rollouts_"):
                    continue
                is_succ = bool(int(np.asarray(z.get("is_success", 0)).item()) != 0)
                if args.heatmap_kind == "success" and not is_succ:
                    continue
                if args.heatmap_kind == "failure" and is_succ:
                    continue
                cands.append(ep_npz)
            finally:
                z.close()
        if cands:
            rng = np.random.default_rng(int(args.seed))
            rng.shuffle(cands)
            cands = cands[: int(args.heatmap_num_episodes)]

        rollouts_dir = _resolve_path(meta.get("rollouts_hdf5_dir"))
        rollouts_dir = rollouts_dir or Path(str(meta.get("rollouts_hdf5_dir", "")))

        for ep_npz in cands:
            z = np.load(str(ep_npz), allow_pickle=True)
            try:
                win_end = np.asarray(z.get("window_end_t_sparse", []), dtype=np.int32).reshape(-1)
                path = np.asarray(z.get("match_seg_idx_sparse", []), dtype=np.int32).reshape(-1)
                is_succ = bool(int(np.asarray(z.get("is_success", 0)).item()) != 0)
            finally:
                z.close()
            if win_end.size == 0:
                continue

            hdf5_name = ep_npz.stem  # includes .hdf5
            # Locate hdf5 under rollouts_dir/{success,failure}
            cand0 = Path(rollouts_dir) / "success" / hdf5_name
            cand1 = Path(rollouts_dir) / "failure" / hdf5_name
            hdf5_path = cand0 if cand0.exists() else (cand1 if cand1.exists() else None)
            if hdf5_path is None:
                continue

            cache_path = _locate_episode_embed_cache(embed_cache_dir, hdf5_path)
            if cache_path is None:
                continue

            th, eh, tw, ew = _load_series_arrays(cache_path, series=win_series)
            if eh is None:
                continue
            # Build maps
            high_map = {}
            wrist_map = {}
            if th is not None and eh is not None:
                for t, e in zip(np.asarray(th, dtype=np.int32).reshape(-1), np.asarray(eh, dtype=np.float32), strict=False):
                    high_map[int(t)] = np.asarray(e, dtype=np.float32).reshape(-1)
            if tw is not None and ew is not None:
                for t, e in zip(np.asarray(tw, dtype=np.int32).reshape(-1), np.asarray(ew, dtype=np.float32), strict=False):
                    wrist_map[int(t)] = np.asarray(e, dtype=np.float32).reshape(-1)

            # Build raw window embedding arrays
            if camera_mode == "both" and camera_fusion in ("dist_min", "dist_mean"):
                Xh_raw = np.stack([high_map[int(t)] for t in win_end.tolist()], axis=0)
                Xw_raw = np.stack([wrist_map[int(t)] for t in win_end.tolist()], axis=0)
                Xh_lat = _preprocess(task, "high", Xh_raw)
                Xw_lat = _preprocess(task, "wrist", Xw_raw)
                ch = _diffusion_cost_matrix(model=_get_model(task, "high"), sched=sched, X_lat=Xh_lat, num_segments=num_segments, t_eval=t_eval, noise_samples=noise_samples, device=device)
                cw = _diffusion_cost_matrix(model=_get_model(task, "wrist"), sched=sched, X_lat=Xw_lat, num_segments=num_segments, t_eval=t_eval, noise_samples=noise_samples, device=device)
                cost_mat = np.minimum(ch, cw) if camera_fusion == "dist_min" else (0.5 * (ch + cw))
            elif camera_mode == "both" and camera_fusion in ("emb_mean", "emb_concat"):
                Xf_list = []
                for t in win_end.tolist():
                    eh0 = high_map[int(t)]
                    ew0 = wrist_map[int(t)]
                    if camera_fusion == "emb_mean":
                        ef = 0.5 * (eh0 + ew0)
                    else:
                        ef = np.concatenate([eh0, ew0], axis=0)
                    Xf_list.append(np.asarray(ef, dtype=np.float32).reshape(-1))
                Xf_raw = np.stack(Xf_list, axis=0)
                Xf_lat = _preprocess(task, "fused", Xf_raw)
                cost_mat = _diffusion_cost_matrix(model=_get_model(task, "fused"), sched=sched, X_lat=Xf_lat, num_segments=num_segments, t_eval=t_eval, noise_samples=noise_samples, device=device)
            else:
                key = "single"
                if camera_mode == "high":
                    X_raw = np.stack([high_map[int(t)] for t in win_end.tolist()], axis=0)
                else:
                    X_raw = np.stack([wrist_map[int(t)] for t in win_end.tolist()], axis=0)
                X_lat = _preprocess(task, key, X_raw)
                cost_mat = _diffusion_cost_matrix(model=_get_model(task, key), sched=sched, X_lat=X_lat, num_segments=num_segments, t_eval=t_eval, noise_samples=noise_samples, device=device)

            try:
                import matplotlib.pyplot as plt

                fig = plt.figure(figsize=(10, 6))
                ax = fig.add_subplot(1, 1, 1)
                im = ax.imshow(cost_mat.astype(np.float32).T, aspect="auto", origin="lower")  # (seg,K)
                fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
                ax.plot(np.arange(len(path)), path.astype(np.float32), color="white", linewidth=2.0, alpha=0.9, label="decoded_path")
                ax.set_title(f"Diffusion cost heatmap ({'succ' if is_succ else 'fail'})\\n{hdf5_path.name}")
                ax.set_xlabel("window_index")
                ax.set_ylabel("seg_idx")
                ax.legend(loc="best")
                fig.tight_layout()
                out_png = out_dir / f"segmatch50_diffusion_heatmap__{hdf5_path.stem}.png"
                fig.savefig(str(out_png), dpi=200)
                plt.close(fig)
                heatmap_paths.append(str(out_png))
            except Exception:
                pass

    summary = {
        "out_cache_dir": str(out_dir),
        "cfg_id": str(cfg_id),
        "task": str(task),
        "key": str(key_main),
        "confusion_acc": float(acc),
        "confusion_npz": str(out_npz),
        "confusion_png": (str(conf_png) if conf_png is not None else None),
        "rollouts_cost_hist_png": (str(hist_png) if hist_png is not None else None),
        "n_rollouts_success": int(len(succ_cost)),
        "n_rollouts_failure": int(len(fail_cost)),
        "heatmap_pngs": heatmap_paths,
    }
    _write_json(out_dir / "segmatch50_diffusion_check_summary.json", summary)
    print(json.dumps(summary, indent=2, ensure_ascii=False))


if __name__ == "__main__":
    main(tyro.cli(Args))


